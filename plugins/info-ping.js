import speed from 'performance-now'
import { exec } from 'child_process'
import moment from 'moment-timezone'
import os from 'os'
import fetch from 'node-fetch'

let handler = async (m, { conn }) => {
  try {
    await conn.sendMessage(m.chat, { react: { text: 'ğŸš€', key: m.key } })

    let timestamp = speed()
    let latensi = speed() - timestamp

    const start = new Date().getTime()
    await conn.sendMessage(m.chat, { text: `*ğŸ›°ï¸ CALCULANDO PING...*\n> Espere un momento â³` }, { quoted: m })
    const end = new Date().getTime()
    const latency = end - start

    // Datos del sistema
    const uptime = process.uptime()
    const hours = Math.floor(uptime / 3600)
    const minutes = Math.floor((uptime % 3600) / 60)
    const secondsUp = Math.floor(uptime % 60)
    const uptimeFormatted = `${hours}h ${minutes}m ${secondsUp}s`

    const totalRAM = os.totalmem() / 1024 / 1024
    const usedRAM = process.memoryUsage().heapUsed / 1024 / 1024
    const freeRAM = totalRAM - usedRAM

    const cpuModel = os.cpus()[0].model
    const cpuCores = os.cpus().length
    const cpuSpeed = os.cpus()[0].speed
    const platform = os.platform()
    const architecture = os.arch()
    const hostname = os.hostname()
    const user = os.userInfo().username
    const fechaHora = moment().tz('America/Lima').format('YYYY/MM/DD, h:mm:ss A')

    // CÃ¡lculo CPU promedio
    const cpuLoad = os.loadavg()[0] / cpuCores * 100
    const cpuUsage = Math.min(cpuLoad, 100)

    // Barras visuales
    const makeBar = (value, max = 100, size = 10) => {
      const filled = Math.round((value / max) * size)
      const empty = size - filled
      return 'â–°'.repeat(filled) + 'â–±'.repeat(empty)
    }

    const ramBar = makeBar((usedRAM / totalRAM) * 100)
    const cpuBar = makeBar(cpuUsage)

    const thumbBuffer = Buffer.from(await (await fetch('https://i.postimg.cc/RhBzW7B9/X-Host.jpg')).arrayBuffer())

    exec(`neofetch --stdout`, async () => {
      let response = 
`â•­â”€â”€â”€ã€” âš™ï¸ *PANEL DE RENDIMIENTO* âš™ï¸ ã€•
â”‚ ğŸ“¶ *Ping:* ${latency} ms
â”‚ âš¡ *Velocidad:* ${latensi.toFixed(2)} ms
â”‚ ğŸ—“ï¸ *Fecha:* ${fechaHora}
â”‚ ğŸŒ *Zona Horaria:* Lima ğŸ‡µğŸ‡ª
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–

â•­â”€â”€â”€ã€” ğŸ’» *ESTADO DEL SISTEMA* ğŸ’» ã€•
â”‚ ğŸ’½ *RAM usada:* ${usedRAM.toFixed(2)} / ${totalRAM.toFixed(0)} MB
â”‚ ğŸ§  *Uso CPU:* ${cpuUsage.toFixed(2)}%
â”‚ 
â”‚ ğŸ’¾ RAM: ${ramBar}
â”‚ ğŸ”‹ CPU: ${cpuBar}
â”‚ 
â”‚ ğŸ§© *CPU:* ${cpuModel}
â”‚ âš™ï¸ *Cores:* ${cpuCores}
â”‚ ğŸ—ï¸ *Velocidad:* ${cpuSpeed} MHz
â”‚ ğŸ’» *Plataforma:* ${platform.toUpperCase()}
â”‚ ğŸ§± *Arquitectura:* ${architecture.toUpperCase()}
â”‚ ğŸ–¥ï¸ *Hostname:* ${hostname}
â”‚ ğŸ‘¤ *Usuario:* ${user}
â”‚ â±ï¸ *Uptime:* ${uptimeFormatted}
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–

â•­â”€â”€â”€ã€” ğŸ¤– *INFORMACIÃ“N DEL BOT* ğŸ¤– ã€•
â”‚ ğŸŒ¸ *Nombre:* MiyukiBot-MD
â”‚ ğŸª„ *VersiÃ³n:* 2.5.0 Beta
â”‚ ğŸ’¬ *Lenguaje:* JavaScript (Node.js)
â”‚ ğŸ§  *Framework:* Baileys MultiDevice
â”‚ ğŸ“¡ *Estado:* Online âœ…
â”‚ ğŸ§° *Desarrollador:* Omar Granda
â”‚ ğŸ§© *MÃ³dulos activos:* Info, Tools, Admin, DiversiÃ³n
â”‚ â˜ï¸ *Infraestructura:* VPS Linux - 24/7
â”‚ ğŸ”— *Repositorio:* github.com/OmarGranda/MiyukiBot-MD
â”‚ ğŸŒ *Soporte:* Telegram / WhatsApp / Discord
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–

ğŸª¶ *Frase del DÃ­a:* â€œEl mejor bot no es el mÃ¡s rÃ¡pido, sino el que nunca se detiene.â€ ğŸ’«
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸŒ¸ *MiyukiBot-MD* â€” TecnologÃ­a japonesa, precisiÃ³n peruana ğŸ‡µğŸ‡ª
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`

      await conn.sendMessage(m.chat, {
        text: response,
        mentions: [m.sender],
        contextInfo: {
          externalAdReply: {
            title: 'ğŸŒ¸ ğ™ˆğ™ğ™®ğ™ªğ™ ğ™ğ˜½ğ™¤ğ™©-ğ™ˆğ˜¿',
            body: 'âš™ï¸ Dashboard del Sistema y Estado',
            thumbnail: thumbBuffer,
            sourceUrl: 'https://github.com/OmarGranda/MiyukiBot-MD',
            mediaType: 1,
            renderLargerThumbnail: true
          }
        }
      }, { quoted: m })

      await conn.sendMessage(m.chat, { react: { text: 'âœ…', key: m.key } })
    })
  } catch (error) {
    console.error(error)
    await conn.sendMessage(m.chat, { text: 'âŒ OcurriÃ³ un error al calcular el ping.' }, { quoted: m })
  }
}

handler.help = ['ping', 'status', 'estado', 'p']
handler.tags = ['info']
handler.command = ['ping', 'status', 'estado', 'p']
handler.register = true

export default handler